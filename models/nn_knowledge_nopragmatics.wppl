
var num_utterances = 3
var num_worlds = 3
var h_size = 10

var sampleArray = function(a){
  var i = randomInteger(a.length)
  return a[i]
}

var sumScalars = function(a){
  var acc = function(b,sum){
    return b.length>0?  acc(b.slice(1),ad.scalar.add(sum,b[0])) :  sum
  }
  return acc(a,0)
}

var nnparam = function(a, b) {
  return param([a, b], 0, 0.1);
};

var network = function(x, W, b) {
  var input = T.reshape(T.concat(x[0],x[1]),[x[0].length+x[1].length,1])
  var h = T.tanh(T.add(T.dot(W[0], input), b[0]));
  var output = T.add(T.dot(W[1], h), b[1]);
  return T.sumreduce(output)
};

var worlds = [Vector([1,0,0]),Vector([0,1,0]),Vector([0,0,1])]

var knowledge_states1 = 
  [[Vector([1,0,0])],//some not all
  [Vector([0,1,0])],//some not all
  [Vector([0,0,1])]]// all
var knowledge_states2 = 
  [[Vector([1,0,0]),Vector([0,1,0]),Vector([0,0,1])],
  [Vector([0,0,1])]]//all

var knowledgePrior = function(knowledge_states){
  //var i = randomInteger(knowledge_states.length)
  //return knowledge_states[i]
  return sampleArray(knowledge_states)
}


var literalListener = cache(function(utterance,W,b,knowledge_states) {
  Enumerate(function(){
    var knowledge_state = knowledgePrior(knowledge_states)
    var world = sampleArray(knowledge_state)

    factor(network([world,utterance],W,b))

    return knowledge_state
  })
})


var sampleMatrixGaussian = function(dims,mean,variance,guide_mean){
  var length = dims[0]*dims[1]
  var g = sample(diagCovGaussianERP,[Vector(repeat(length, constF(mean))),Vector(repeat(length, constF(variance)))],
    {guide: [diagCovGaussianERP, [T.reshape(guide_mean,[length,1]),Vector(repeat(length, constF(0.001)))]]})
  return T.reshape(g,dims)
}

var utterance_dict = {'some':Vector([0,0,1]),'all':Vector([1,0,0])}
var utt = function(u){
  return utterance_dict[u]
}

var model = function() {


  var W0_var = nnparam(h_size,num_worlds+num_utterances)
  var W1_var = nnparam(1,h_size)
  var b0_var = nnparam(h_size,1)
  var b1_var = nnparam(1,1)

  var W0 = sampleMatrixGaussian([h_size,num_worlds+num_utterances],0,1,W0_var)
  var W1 = sampleMatrixGaussian([1,h_size],0,1,W1_var)
  var b0 = sampleMatrixGaussian([h_size,1],0,1,b0_var)
  var b1 = sampleMatrixGaussian([1,1],0,1,b1_var)


  var l1 = literalListener(utt('some'),[W0,W1],[b0,b1],knowledge_states1)
  var l2 = literalListener(utt('all'),[W0,W1],[b0,b1],knowledge_states1)

  var l3 = literalListener(utt('some'),[W0,W1],[b0,b1],knowledge_states2)
  var l4 = literalListener(utt('all'),[W0,W1],[b0,b1],knowledge_states2)

  var lit = literalListener(utt('some'),[W0,W1],[b0,b1],knowledge_states1)

  console.log(lit.hist)
  factor(l3.score([], knowledge_states2[0])*3+
    l4.score([], knowledge_states2[1])*50+
    l1.score([], knowledge_states1[0])*50+
    l1.score([], knowledge_states1[1])*50+
    l2.score([], knowledge_states1[2])*50)

  return W0;
};

// VI.
var params = Optimize(model, {steps: 2000, method: {gd: {stepSize: 0.01}}, estimator: {ELBO: {samples: 1}}});

// Optimized params.
console.log(JSON.stringify(params))